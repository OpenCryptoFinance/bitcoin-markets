{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddbe501",
   "metadata": {},
   "source": [
    "\n",
    "# Artificial Neural Networks (ANN): The concept of artificial neural networks has its roots in the work of Warren McCulloch and Walter Pitts in the 1940s. The development of modern neural networks, including backpropagation, can be attributed to multiple researchers including Paul Werbos in 1974, David Rumelhart and James McClelland in 1986, and Geoffrey Hinton in the 2000s\n",
    "\n",
    "Boulouma A., 2023\n",
    "\n",
    "Artificial neural networks are a type of machine learning algorithm that are modeled after the structure of the human brain. An ANN consists of layers of interconnected nodes, with each node performing a simple mathematical operation. The equations for a feedforward ANN with one hidden layer are:\n",
    "\n",
    "$$z_j = \\sum_{i=1}^n w_{ij} x_i + b_j$$\n",
    "\n",
    "$$h_j = \\sigma(z_j)$$\n",
    "\n",
    "$$y_k = \\sum_{j=1}^m v_{jk} h_j + c_k$$\n",
    "\n",
    "where $x_i$ is the input to the network, $w_{ij}$ is the weight between the $i$-th input and $j$-th hidden layer node, $b_j$ is the bias of the $j$-th hidden layer node, $z_j$ is the weighted sum of the inputs to the $j$-th hidden layer node, $\\sigma(\\cdot)$ is the activation function (e.g. sigmoid, ReLU), $h_j$ is the output of the $j$-th hidden layer node, $v_{jk}$ is the weight between the $j$-th hidden layer node and the $k$-th output node, $c_k$ is the bias of the $k$-th output node, and $y_k$ is the output of the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
