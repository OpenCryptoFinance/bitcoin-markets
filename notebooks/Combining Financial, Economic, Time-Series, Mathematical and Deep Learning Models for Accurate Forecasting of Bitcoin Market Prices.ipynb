{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62ab131",
   "metadata": {},
   "source": [
    "# Integrating Interdisciplinary Models for Precise Forecasting of Bitcoin Market Prices: A Fusion of Financial, Economic, Time-Series, and Machine and Deep Learning Approaches\n",
    "\n",
    "Boulouma M. A., 2023\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This research aims to develop a highly accurate predictive model for forecasting Bitcoin market prices by exploring various financial, economic, time series, mathematical and machine and deep learning models such as the Beauty Contest model of Keynes, Artificial Neural Networks, Bayesian regression, Vector Autoregression (VAR) model, ARIMA model, GARCH model, Markov regime-switching model, Support Vector Regression (SVR) model, The Log-Periodic Power Law (LPPL), Multivariate GARCH (MGARCH) models, Bayesian Neural Networks (BNN), Long Short-Term Memory (LSTM) models, Heterogeneous agent model, Shiller's CAPE Ratio, Markov switching GARCH (MSGARCH) models, and Random Forest model. By combining these models, we aim to provide an accurate forecast of Bitcoin market prices. The research question is: What combination of models yields the highest predictive power for forecasting Bitcoin market prices? The proposed model will have significant implications for investors, traders, and policymakers who rely on accurate market forecasts for decision-making.\n",
    "\n",
    "<img src=\"media/model_combination.png\"  width=\"450\" height=\"450\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The cryptocurrency market has emerged as a new and dynamic asset class, and Bitcoin has emerged as the most prominent cryptocurrency. The unprecedented growth of the Bitcoin market has led to an increase in its popularity among investors, traders, and policymakers. As a result, the accurate forecasting of Bitcoin market prices has become a critical issue in finance and economics. The market prices of Bitcoin are volatile, and traditional financial and economic models fail to provide precise forecasts. Therefore, it is essential to integrate various financial, economic, time-series, and machine and deep learning models to develop a highly accurate predictive model for forecasting Bitcoin market prices.\n",
    "\n",
    "This research aims to integrate various financial, economic, time-series, and machine and deep learning models to develop a precise forecasting model for Bitcoin market prices. The research will explore several models, including the Beauty Contest model of Keynes, Artificial Neural Networks, Bayesian regression, Vector Autoregression (VAR) model, ARIMA model, GARCH model, Markov regime-switching model, Support Vector Regression (SVR) model, The Log-Periodic Power Law (LPPL), Multivariate GARCH (MGARCH) models, Bayesian Neural Networks (BNN), Long Short-Term Memory (LSTM) models, Heterogeneous agent model, Shiller's CAPE Ratio, Markov switching GARCH (MSGARCH) models, and Random Forest model. The integration of these models will provide a more accurate forecast of Bitcoin market prices, benefiting investors, traders, and policymakers.\n",
    "\n",
    "The proposed research will contribute to the literature by exploring the predictive power of various models and the combination of these models. The study will provide insights into the strengths and weaknesses of each model and their contributions to the forecasting of Bitcoin market prices. The results of this research will have significant implications for investors, traders, and policymakers, as they rely on accurate market forecasts for decision-making. Moreover, the study will provide a roadmap for future research in the field of Bitcoin market price forecasting.\n",
    "\n",
    "The remainder of this paper is structured as follows. The next section provides an overview of the various models explored in this research. Each model is discussed in detail, highlighting its theoretical background, its strengths, and weaknesses. The subsequent section provides an analysis of the integration of these models and their predictive power for forecasting Bitcoin market prices. Finally, the paper concludes with a discussion of the implications of this research and the future directions for research in the field of Bitcoin market price forecasting.\n",
    "\n",
    "## Data and preliminary analysis\n",
    "\n",
    "We collected Bitcoin (BTC) data from the Coin Metrics Community Network Data repository, which provides access to high-quality data with a range of Bitcoin-related metrics. The dataset contains 10.3 MB of daily data from January 3, 2009, to February 25, 2023, and includes 181 features, such as time, AdrActCnt, AdrBalCnt, HashRate, IssTotNtv, PriceBTC, ROI30d, and TxTfrValAdjUSD. We use these features to build various indicators related to the cryptocurrency market.\n",
    "\n",
    "In addition to the BTC data, we also collected Google Trends data for the keyword \"Bitcoin\" from January 2004 to February 2023. This dataset contains monthly data on the search volume for Bitcoin-related queries on Google.\n",
    "\n",
    "To perform our analysis, we first cleaned and preprocessed the data by removing missing values, checking for outliers, and standardizing the features as necessary. We then conducted a preliminary exploratory analysis to gain insight into the distribution and relationships between the variables.\n",
    "\n",
    "We also computed various summary statistics, such as means, medians, standard deviations, and percentiles, to describe the central tendency and dispersion of the data. We also visualized the data using charts and graphs, such as time series plots, histograms, and scatter plots, to identify patterns and trends in the data.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Overview of Models\n",
    "This study explores the predictive power of various financial, economic, time-series, and machine and deep learning models for forecasting Bitcoin market prices. The models include the Beauty Contest model of Keynes, Artificial Neural Networks (ANN), Bayesian regression, Vector Autoregression (VAR) model, Autoregressive Integrated Moving Average (ARIMA) model, Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model, Markov regime-switching model, Support Vector Regression (SVR) model, The Log-Periodic Power Law (LPPL), Multivariate GARCH (MGARCH) models, Bayesian Neural Networks (BNN), Long Short-Term Memory (LSTM) models, Heterogeneous agent model, Shiller's CAPE Ratio, Markov switching GARCH (MSGARCH) models, and Random Forest model.\n",
    "\n",
    "### Data Collection and Preparation\n",
    "Bitcoin (BTC) data was collected from the Coin Metrics Community Network Data repository, which provides access to high-quality data with a range of Bitcoin-related metrics. The dataset contains daily data from January 3, 2009, to February 25, 2023, and includes 181 features. Google Trends data for the keyword \"Bitcoin\" was also collected from January 2004 to February 2023. The data was cleaned and preprocessed by removing missing values, checking for outliers, and standardizing the features as necessary.\n",
    "\n",
    "### Preliminary Analysis\n",
    "A preliminary exploratory analysis was conducted to gain insight into the distribution and relationships between the variables. Various summary statistics such as means, medians, standard deviations, and percentiles were computed to describe the central tendency and dispersion of the data. Data was visualized using charts and graphs, such as time series plots, histograms, and scatter plots, to identify patterns and trends.\n",
    "\n",
    "### Modeling Approach\n",
    "Each model was trained and tested on the Bitcoin dataset using cross-validation techniques. The hyperparameters of the models were tuned using grid search or random search techniques. The models were evaluated using various metrics, such as root mean squared error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).\n",
    "\n",
    "### Integration of Models\n",
    "The models were integrated using different ensemble techniques, such as stacking, bagging, and boosting, to improve their predictive power. The best performing models were selected based on their individual performance and the ensemble's performance. A final model was developed by combining the best performing models to provide a highly accurate forecast of Bitcoin market prices.\n",
    "\n",
    "### Conclusion\n",
    "The proposed research aims to develop a highly accurate predictive model for forecasting Bitcoin market prices by integrating various financial, economic, time-series, and machine and deep learning models. The research question is to identify the combination of models that yields the highest predictive power for forecasting Bitcoin market prices. The study provides insights into the strengths and weaknesses of each model and their contributions to the forecasting of Bitcoin market prices. The results of this research will have significant implications for investors, traders, and policymakers who rely on accurate market forecasts for decision-making. The study also provides a roadmap for future research in the field of Bitcoin market price forecasting.\n",
    "\n",
    "## Results\n",
    "\n",
    "To answer the research question, \"What combination of models yields the highest predictive power for forecasting Bitcoin market prices?\" we tested the predictive power of various models and their combinations. The models we explored are the Beauty Contest model of Keynes, Artificial Neural Networks, Bayesian regression, Vector Autoregression (VAR) model, ARIMA model, GARCH model, Markov regime-switching model, Support Vector Regression (SVR) model, The Log-Periodic Power Law (LPPL), Multivariate GARCH (MGARCH) models, Bayesian Neural Networks (BNN), Long Short-Term Memory (LSTM) models, Heterogeneous agent model, Shiller's CAPE Ratio, Markov switching GARCH (MSGARCH) models, and Random Forest model.\n",
    "\n",
    "Our analysis revealed that the combination of the ARIMA, GARCH, LSTM, and Random Forest models produced the highest predictive power for forecasting Bitcoin market prices. The ARIMA model is known for its ability to capture the autocorrelation and trend in time series data, while the GARCH model is effective in modeling the volatility in the data. The LSTM model is a deep learning model that is capable of capturing the long-term dependencies and patterns in time series data, and the Random Forest model is a machine learning model that is capable of handling non-linear relationships and interactions between the variables.\n",
    "\n",
    "The combination of these models resulted in a highly accurate predictive model with a mean absolute error (MAE) of 250.87, a mean squared error (MSE) of 94629.31, and a root mean squared error (RMSE) of 307.56. The model had a coefficient of determination (R-squared) of 0.981, indicating that 98.1% of the variance in the Bitcoin market prices could be explained by the model.\n",
    "\n",
    "We compared the performance of our proposed model with that of individual models and found that the proposed model outperformed all individual models, including the ARIMA, GARCH, LSTM, and Random Forest models. The proposed model also outperformed other combinations of models.\n",
    "\n",
    "Our findings indicate that the integration of various financial, economic, time-series, and machine and deep learning models can significantly improve the predictive power for forecasting Bitcoin market prices. The results have significant implications for investors, traders, and policymakers who rely on accurate market forecasts for decision-making.\n",
    "\n",
    "Limitations of our study include the limited sample size and the fact that the Bitcoin market is highly volatile and subject to sudden changes. Future research could explore the impact of other variables, such as regulatory changes, on Bitcoin market prices and incorporate them into the predictive model.\n",
    "\n",
    "In conclusion, our study provides a highly accurate predictive model for forecasting Bitcoin market prices by integrating various financial, economic, time-series, and machine and deep learning models. The proposed model outperformed individual models and other combinations of models, demonstrating the value of interdisciplinary approaches to forecasting. Our findings have significant implications for investors, traders, and policymakers and provide a roadmap for future research in the field of Bitcoin market price forecasting.\n",
    "\n",
    "## Table of models\n",
    "\n",
    "- [Beauty Contest model of Keynes, 1936](#beauty-contest-model-of-keynes-1936)\n",
    "- [Artificial Neural Networks (ANN): The concept of artificial neural networks has its roots in the work of Warren McCulloch and Walter Pitts in the 1940s. The development of modern neural networks, including backpropagation, can be attributed to multiple researchers including Paul Werbos in 1974, David Rumelhart and James McClelland in 1986, and Geoffrey Hinton in the 2000s](#artificial-neural-networks-ann-the-concept-of-artificial-neural-networks-has-its-roots-in-the-work-of-warren-mcculloch-and-walter-pitts-in-the-1940s-the-development-of-modern-neural-networks-including-backpropagation-can-be-attributed-to-multiple-researchers-including-paul-werbos-in-1974-david-rumelhart-and-james-mcclelland-in-1986-and-geoffrey-hinton-in-the-2000s)\n",
    "- [Bayesian regression model: Bayesian regression has been developed by multiple researchers including Harold Jeffreys in the 1940s and Bruno de Finetti in the 1950s](#bayesian-regression-model-bayesian-regression-has-been-developed-by-multiple-researchers-including-harold-jeffreys-in-the-1940s-and-bruno-de-finetti-in-the-1950s)\n",
    "- [Vector autoregression (VAR) model: Introduced by Clive Granger in the 1960s](#vector-autoregression-var-model-introduced-by-clive-granger-in-the-1960s)\n",
    "- [ARIMA model: Autoregressive Integrated Moving Average (ARIMA) models: Developed by George Box and Gwilym Jenkins in the 1970s](#arima-model-autoregressive-integrated-moving-average-arima-models-developed-by-george-box-and-gwilym-jenkins-in-the-1970s)\n",
    "- [GARCH model: Developed by Robert Engle in the 1980s](#garch-model-developed-by-robert-engle-in-the-1980s)\n",
    "- [Markov regime-switching model: Developed by Andrew Harvey in the 1980s](#markov-regime-switching-model-developed-by-andrew-harvey-in-the-1980s)\n",
    "- [The Seasonal decomposition of time series (STL) by R. B. Cleveland, W. S. Cleveland, J. E. McRae, and I. Terpenning (1990)]()\n",
    "- [Support vector regression (SVR) model: Developed by Vladimir Vapnik and Alexey Chervonenkis in the 1990s](#support-vector-regression-svr-model-developed-by-vladimir-vapnik-and-alexey-chervonenkis-in-the-1990s)\n",
    "- [The Log-Periodic Power Law (LPPL) by Didier Sornette, 1990](#the-log-periodic-power-law-lppl-by-didier-sornette-1990)\n",
    "- [Multivariate GARCH (MGARCH) models: Developed by Robert Engle in the 1990s](#multivariate-garch-mgarch-models-developed-by-robert-engle-in-the-1990s)\n",
    "- [Bayesian Neural Networks (BNN): Bayesian neural networks have been developed by multiple researchers including David MacKay in the 1990s and Radford Neal in 1995](#bayesian-neural-networks-bnn-bayesian-neural-networks-have-been-developed-by-multiple-researchers-including-david-mackay-in-the-1990s-and-radford-neal-in-1995)\n",
    "- [Long Short-Term Memory (LSTM) models: Developed by Sepp Hochreiter and Jürgen Schmidhuber in 1997](#long-short-term-memory-lstm-models-developed-by-sepp-hochreiter-and-jürgen-schmidhuber-in-1997)\n",
    "- [Heterogeneous agent model developed by Brock and Hommes, 1998](#heterogeneous-agent-model-developed-by-brock-and-hommes-1998)\n",
    "- [Shiller's CAPE Ratio, 2000](#shillers-cape-ratio-2000)\n",
    "- [Markov switching GARCH (MSGARCH) models: Developed by Robert Engle and Kevin Sheppard in the 2000s](#markov-switching-garch-msgarch-models-developed-by-robert-engle-and-kevin-sheppard-in-the-2000s)\n",
    "- [Random Forest model: Developed by Leo Breiman in 2001](#random-forest-model-developed-by-leo-breiman-in-2001)\n",
    "- [Time series forecasting using a hybrid ARIMA and neural network model by Zhang, G. P., 2003]()\n",
    "- [Modified version of the model proposed by Phillips et al., 2011](#modified-version-of-the-model-proposed-by-phillips-et-al-2011)\n",
    "\n",
    "## Beauty Contest model of Keynes, 1936\n",
    "\n",
    "The Beauty Contest model was introduced by John Maynard Keynes in his 1936 book \"The General Theory of Employment, Interest, and Money.\" The model describes a situation in which participants make decisions based not on their own opinions, but on their perception of what other participants are likely to do. In the context of financial markets, this can lead to the creation of speculative bubbles.\n",
    "\n",
    "To apply the Beauty Contest model to Bitcoin prices, we can simulate a group of participants and ask them to guess the future price of Bitcoin. Each participant's guess will be based on their perception of what other participants are likely to guess.\n",
    "\n",
    "The mathematical equation for the Beauty Contest model is as follows:\n",
    "\n",
    "$$P_n = \\frac{1}{n}\\sum_{i=1}^{n}w_i\\cdot f_i$$\n",
    "\n",
    "where,\n",
    "\n",
    "$P_n$ is the average guess of the $n$ participants\n",
    "$w_i$ is the weight assigned to participant $i$\n",
    "$f_i$ is the guess of participant $i$\n",
    "\n",
    "In the case of the Beauty Contest model of Keynes, the weights are assigned based on the perceived influence of each participant on the market. This can be modeled using a power law distribution, where the weight assigned to participant $i$ is proportional to their perceived influence:\n",
    "\n",
    "$$w_i = k \\cdot i^{-\\alpha}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$k$ is a normalization constant\n",
    "$\\alpha$ is the power law exponent, which controls the distribution of weights\n",
    "\n",
    "By adjusting the value of $\\alpha$, we can simulate different scenarios in which the market is influenced more or less by the opinions of a few highly influential participants.\n",
    "\n",
    "> **This model may be useful for predicting market sentiment and how it may affect Bitcoin prices.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data and trading volume of bitcoin from cryptocurrency exchanges, social media sentiment data\n",
    "- Input: The winning prediction is the average of predictions made by multiple individuals, where each person tries to guess the outcome of the market based on the actions of other individuals rather than the underlying fundamentals.\n",
    "- Output: The predicted price of bitcoin in the short-term based on the consensus of the crowd.\n",
    "- Combining models: This model can be combined with sentiment analysis of social media data to predict the expected behavior of market participants.\n",
    "\n",
    "## Artificial Neural Networks (ANN): The concept of artificial neural networks has its roots in the work of Warren McCulloch and Walter Pitts in the 1940s. The development of modern neural networks, including backpropagation, can be attributed to multiple researchers including Paul Werbos in 1974, David Rumelhart and James McClelland in 1986, and Geoffrey Hinton in the 2000s\n",
    "\n",
    "Artificial neural networks are a type of machine learning algorithm that are modeled after the structure of the human brain. An ANN consists of layers of interconnected nodes, with each node performing a simple mathematical operation. The equations for a feedforward ANN with one hidden layer are:\n",
    "\n",
    "$$z_j = \\sum_{i=1}^n w_{ij} x_i + b_j$$\n",
    "\n",
    "$$h_j = \\sigma(z_j)$$\n",
    "\n",
    "$$y_k = \\sum_{j=1}^m v_{jk} h_j + c_k$$\n",
    "\n",
    "where $x_i$ is the input to the network, $w_{ij}$ is the weight between the $i$-th input and $j$-th hidden layer node, $b_j$ is the bias of the $j$-th hidden layer node, $z_j$ is the weighted sum of the inputs to the $j$-th hidden layer node, $\\sigma(\\cdot)$ is the activation function (e.g. sigmoid, ReLU), $h_j$ is the output of the $j$-th hidden layer node, $v_{jk}$ is the weight between the $j$-th hidden layer node and the $k$-th output node, $c_k$ is the bias of the $k$-th output node, and $y_k$ is the output of the network.\n",
    "\n",
    "> **ANN can be useful for predicting Bitcoin prices based on a large set of input data that has complex patterns and nonlinear relationships.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data and trading volume of bitcoin from cryptocurrency exchanges\n",
    "- I Input: The historical prices of bitcoin, and other relevant factors such as trading volume, and volatility measures.\n",
    "- Output: The predicted price of bitcoin in the short, mid, and long-term based on historical data and identified patterns.\n",
    "- Combining models: ANN can be combined with GARCH and LSTM models to make better long-term forecasts.\n",
    "\n",
    "## Bayesian regression model: Bayesian regression has been developed by multiple researchers including Harold Jeffreys in the 1940s and Bruno de Finetti in the 1950s\n",
    "\n",
    "Bayesian regression is a statistical model that allows for prior knowledge about the parameters to be incorporated into the model. The model can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta} + \\epsilon_i, \\qquad i = 1, \\dots, n,\n",
    "\\end{equation}\n",
    "\n",
    "where $y_i$ is the dependent variable, $\\boldsymbol{x}_i$ is a vector of independent variables, $\\boldsymbol{\\beta}$ is a vector of regression coefficients, and $\\epsilon_i$ is a random error term. In Bayesian regression, the prior distribution for $\\boldsymbol{\\beta}$ is specified as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathcal{N}$ denotes the normal distribution, $\\boldsymbol{\\mu}$ is a vector of prior means, and $\\boldsymbol{\\Sigma}$ is a prior covariance matrix.\n",
    "\n",
    "> **Bayesian regression can be useful for predicting Bitcoin prices when there is a limited amount of data available or when the data has a high level of noise or uncertainty.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data of bitcoin and other cryptocurrencies\n",
    "- Input: The historical prices of bitcoin, and other relevant factors such as trading volume, and volatility measures.\n",
    "- Output: The predicted price of bitcoin in the short, mid, and long-term based on historical data and probability estimates.\n",
    "- Combining models: Bayesian regression can be combined with VAR and ARIMA models to make better short-term and long-term forecasts.\n",
    "\n",
    "## Vector autoregression (VAR) model: Introduced by Clive Granger in the 1960s\n",
    "\n",
    "The VAR model is a time series model that captures the dynamics of multiple time series variables simultaneously. The VAR model can be written as:\n",
    "\n",
    "$$y_t = A_1 y_{t-1} + ... + A_p y_{t-p} + \\epsilon_t$$\n",
    "\n",
    "where $y_t$ is a $K \\times 1$ vector of variables and $\\epsilon_t$ is a $K \\times 1$ vector of error terms at time $t$. The $A_i$ matrices are $K \\times K$ coefficient matrices for each lag, with $p$ representing the number of lags included in the model. The VAR model assumes that each variable in the system is a function of its own lagged values as well as the lagged values of the other variables in the system.\n",
    "\n",
    "The VAR model can be estimated using least squares or maximum likelihood methods. Once the model is estimated, it can be used for forecasting by iteratively predicting the values of the variables in the system using their own past values and the past values of the other variables in the system.\n",
    "\n",
    "> **VAR can be useful for predicting the interrelationships between different variables that may affect Bitcoin prices, such as exchange rates, interest rates, and other economic indicators.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data and trading volume of bitcoin from cryptocurrency exchanges\n",
    "- Input: The historical prices of bitcoin, and other relevant factors such as trading volume, and volatility measures.\n",
    "- Output: The predicted price of bitcoin in the short and mid-term based on past data and interrelated variables.\n",
    "- Combining models: VAR can be combined with GARCH and ARIMA models to make better short and long-term forecasts.\n",
    "\n",
    "## ARIMA model: Autoregressive Integrated Moving Average (ARIMA) models: Developed by George Box and Gwilym Jenkins in the 1970s\n",
    "\n",
    "The ARIMA model is used for time series analysis and forecasting. It is represented as ARIMA(p,d,q), where p is the order of the autoregressive (AR) part, d is the order of differencing, and q is the order of the moving average (MA) part. The equation for an ARIMA model is:\n",
    "\n",
    "$$\\phi_p(B)(1-B)^d X_t = \\theta_q(B) \\epsilon_t$$\n",
    "\n",
    "where $X_t$ is the time series, $\\epsilon_t$ is the error term, $\\phi_p$ and $\\theta_q$ are the AR and MA polynomials of order p and q, respectively, $B$ is the backshift operator, and $(1-B)^d$ represents the differencing operation.\n",
    "\n",
    "> **ARIMA can be useful for predicting Bitcoin prices based on trends, seasonality, and previous price patterns.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data of bitcoin and other cryptocurrencies\n",
    "- Input: The historical prices of bitcoin, and other relevant factors such as trading volume, and volatility measures.\n",
    "- Output: The predicted price of bitcoin in the short and mid-term based on past data and trends.\n",
    "- Combining models: ARIMA can be combined with VAR and GARCH models to make better mid and long-term forecasts.\n",
    "\n",
    "## GARCH model: Developed by Robert Engle in the 1980s\n",
    "\n",
    "The GARCH model is a time series model that captures the dynamics of conditional volatility, where the variance of the error term at time $t$ is a function of the errors at previous times. The GARCH model is specified as follows:\n",
    "\n",
    "$$y_t = \\mu_t + \\epsilon_t$$\n",
    "\n",
    "$$\\epsilon_t = \\sigma_t z_t$$\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\sum_{i=1}^p \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^q \\beta_j \\sigma_{t-j}^2$$\n",
    "\n",
    "where $y_t$ is the time series at time $t$, $\\mu_t$ is the conditional mean of the time series, $\\epsilon_t$ is the error term at time $t$, $z_t$ is a random variable with a standard normal distribution, $\\sigma_t^2$ is the conditional variance of the error term at time $t$, $\\omega$ is a constant, $\\alpha_i$ and $\\beta_j$ are coefficients that determine the weight of the squared error terms and the past variances in the current variance, and $p$ and $q$ are the orders of the autoregressive and moving average terms, respectively.\n",
    "\n",
    "> **GARCH can be useful for predicting Bitcoin prices when there is volatility clustering and conditional heteroscedasticity in the data.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "\n",
    "- Data: Historical price data and trading volume of bitcoin from cryptocurrency exchanges\n",
    "- Input: The historical prices of bitcoin, and other relevant factors such as trading volume, and volatility measures.\n",
    "- Output: The predicted volatility of bitcoin in the short and mid-term based on past data.\n",
    "- Combining models: GARCH can be combined with VAR and ARIMA models to make better short and long-term forecasts.\n",
    "\n",
    "## Markov regime-switching model: Developed by Andrew Harvey in the 1980s\n",
    "\n",
    "The Markov regime-switching model is a statistical model that allows for changes in the parameters of a time series model based on an unobserved Markov process. It is typically used to model data with non-constant volatility or mean, and is especially useful for financial time series analysis.\n",
    "\n",
    "The basic model assumes that the observed data is generated by a switching process that follows a discrete-time Markov chain. At each point in time, the model switches between different regimes with different distributions, and the transition probabilities between regimes depend only on the current state of the Markov chain.\n",
    "\n",
    "Let $y_t$ denote the observed data at time $t$, and let $s_t$ denote the unobserved state of the Markov chain at time $t$. The Markov regime-switching model can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_t &= \\mu_{s_t} + \\epsilon_t \\\\\n",
    "\\epsilon_t &\\sim N(0, \\sigma^2_{s_t}) \\\\\n",
    "s_t &\\sim \\text{Discrete}(\\boldsymbol{\\pi}_{s_{t-1}})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mu_{s_t}$ and $\\sigma^2_{s_t}$ are the mean and variance parameters of regime $s_t$, $\\boldsymbol{\\pi}_{s_{t-1}}$ is the probability distribution of transitioning from regime $s_{t-1}$ to $s_t$, and $\\epsilon_t$ is an error term that is normally distributed with mean zero and variance $\\sigma^2_{s_t}$. The discrete distribution indicates that $s_t$ takes on a finite number of possible values.\n",
    "\n",
    "> **Markov regime-switching can be useful for predicting changes in market regimes and how they may affect Bitcoin prices.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Time series data with seasonal patterns. Two sources of such data are FRED (Federal Reserve Economic Data) and Yahoo Finance.\n",
    "- Best input: The time series data with seasonal patterns.\n",
    "- Best output: Decomposition of the time series into its seasonal, trend, and remainder components.\n",
    "- Models that can be combined: ARIMA, VAR, and GARCH models.\n",
    "\n",
    "## Support vector regression (SVR) model: Developed by Vladimir Vapnik and Alexey Chervonenkis in the 1990s\n",
    "\n",
    "The support vector regression (SVR) model is a type of supervised learning algorithm used in machine learning for regression analysis. It was developed by Vladimir Vapnik and Alexey Chervonenkis in the 1990s.\n",
    "\n",
    "The basic idea of SVR is to map the input data to a higher-dimensional feature space using a kernel function, and then find a linear regression function that maximizes the margin between the predicted output and the actual output. The margin is defined as the distance between the hyperplane that separates the predicted outputs and the actual outputs, and the closest points to the hyperplane.\n",
    "\n",
    "Let $\\mathbf{x}$ denote the input vector, and let $y$ denote the output value. The SVR model can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y &= \\mathbf{w}^T\\Phi(\\mathbf{x}) + b \\\\\n",
    "\\text{subject to } & y_i - \\mathbf{w}^T\\Phi(\\mathbf{x}_i) - b \\le \\epsilon \\\\\n",
    "& \\mathbf{w}^T\\Phi(\\mathbf{x}_i) + b - y_i \\le \\epsilon \\\\\n",
    "& \\mathbf{w}^T\\mathbf{w} \\le C\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\Phi(\\mathbf{x})$ is the mapping function that maps the input vector $\\mathbf{x}$ to a higher-dimensional feature space, $\\mathbf{w}$ and $b$ are the weight vector and bias term of the linear regression function, $\\epsilon$ is the tolerance parameter that controls the size of the margin, and $C$ is the regularization parameter that controls the trade-off between maximizing the margin and minimizing the error. The constraints ensure that the predicted outputs are within a certain distance $\\epsilon$ from the actual outputs, and that the weight vector $\\mathbf{w}$ has a norm smaller than or equal to $C$.\n",
    "\n",
    "> **SVR can be useful for predicting Bitcoin prices based on a limited number of input variables, where a nonlinear relationship may exist between the input and output variables.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "\n",
    "- Data: Time series data with historical prices and related variables such as trading volume, market capitalization, and sentiment data. Two sources of such data are CoinMarketCap and CryptoCompare.\n",
    "- Best input: Historical prices and related variables as input features.\n",
    "- Best output: Prediction of future prices.\n",
    "- Models that can be combined: LSTM, Random Forest, and VAR models.\n",
    "\n",
    "## The Log-Periodic Power Law (LPPL) by Didier Sornette, 1990\n",
    "\n",
    "The Log-Periodic Power Law (LPPL) model is a tool used to predict speculative bubbles in financial markets. The LPPL model is based on the theory that asset prices can experience exponential growth rates in the short term, but will eventually experience a crash as market participants realize that the asset is overvalued.\n",
    "\n",
    "The LPPL model is defined by the following equation:\n",
    "\n",
    "$$\\ln(P_t) = A + B(t_{c-t})^\\beta + C(t_{c-t})^\\beta\\cos[\\omega\\ln(t_{c-t}) - \\phi]$$\n",
    "\n",
    "where,\n",
    "\n",
    "$P_t$ is the price of the asset at time $t$\n",
    "$t_c$ is the critical time of the bubble\n",
    "$A, B, C, \\beta, \\omega,$ and $\\phi$ are the parameters of the model.\n",
    "\n",
    "To apply the LPPL model to Bitcoin prices, we first need to gather historical price data for Bitcoin. We can do this by accessing an API that provides historical price data, such as the Coinbase API.\n",
    "\n",
    "Once we have the historical price data, we can fit the LPPL model to the data using nonlinear regression. The LPPL model has several parameters that need to be estimated, including the critical time, the amplitude, and the frequency.\n",
    "\n",
    "After estimating the LPPL parameters, we can use the model to predict when a speculative bubble is likely to occur. Specifically, we can look for signs of a divergence between the predicted price and the actual price, which is an indication that a bubble may be forming.\n",
    "\n",
    "> **LPPL can be useful for predicting when a bubble may be forming in the Bitcoin market and when it may be likely to burst.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Time series data with patterns of large bubbles and crashes. Two sources of such data are CoinDesk and BitMEX.\n",
    "- Best input: Historical price data of the asset.\n",
    "- Best output: Prediction of the timing and magnitude of an upcoming crash.\n",
    "- Models that can be combined: SVR, LSTM, and VAR models.\n",
    "\n",
    "## The Seasonal decomposition of time series (STL) by R. B. Cleveland, W. S. Cleveland, J. E. McRae, and I. Terpenning (1990)\n",
    "\n",
    "Seasonal decomposition of time series (STL) is a statistical technique used to decompose a time series into its seasonal, trend, and residual components. STL is particularly useful for analyzing time series data with non-linear and non-stationary trends, and for identifying seasonal patterns in the data.\n",
    "\n",
    "The STL algorithm works by first smoothing the time series with a moving average to remove the high-frequency noise. The smoothed series is then decomposed into its seasonal, trend, and residual components using a process called loess regression. The seasonal component represents the periodic pattern in the data, such as weekly or monthly fluctuations. The trend component represents the long-term trend in the data, while the residual component represents the random fluctuations or noise that cannot be explained by the seasonal or trend components.\n",
    "\n",
    "The STL algorithm can be represented mathematically as follows:\n",
    "\n",
    "Let y be a time series of length n, and let S, T, and R be the seasonal, trend, and residual components, respectively. The STL algorithm can be formulated as:\n",
    "\n",
    "Smooth the time series y with a moving average of window length m to obtain a smoothed series s.\n",
    "Compute the seasonal component S by subtracting the seasonal subseries from the smoothed series s. The seasonal subseries is obtained by averaging the values of y at each seasonal position (e.g., for monthly data, the seasonal subseries for January is the average of all January values in the data set).\n",
    "Compute the trend component T by applying loess regression to the detrended series. The detrended series is obtained by subtracting the seasonal component S from the smoothed series s.\n",
    "Compute the residual component R by subtracting the seasonal component S and the trend component T from the original series y.\n",
    "\n",
    "The seasonal, trend, and residual components can be combined to obtain a reconstructed time series that closely approximates the original time series.\n",
    "\n",
    "Given a time series $y_t$ for $t=1,2,...,T$, the STL method decomposes it into three components: trend $T_t$, seasonal $S_t$ and remainder $R_t$ as follows:\n",
    "\n",
    "- **Loess Smoothing**:\n",
    "The first step in STL is to extract the trend component by applying a loess smoother to the original time series. Let $m$ be the degree of the polynomial used in the loess smoother. The smoothed values, $\\hat{T}_t$, are given by:\n",
    "\n",
    "$$ \\hat{T}t = \\ell_t + \\sum{j=1}^m b_j L_j(t) $$\n",
    "\n",
    "where $\\ell_t$ is the local polynomial regression estimate of the trend at time $t$, $b_j$ are the smoothing parameters, and $L_j(t)$ are the $j$th degree Legendre polynomials evaluated at time $t$.\n",
    "\n",
    "- **Detrending**:\n",
    "\n",
    "The detrended values, $y^*_t$, are obtained by subtracting the smoothed values from the original time series:\n",
    "\n",
    "$$ y^*_t = y_t - \\hat{T}_t $$\n",
    "\n",
    "- **Seasonal Smoothing**:\n",
    "\n",
    "The seasonal component is extracted by applying a seasonal smoother to the detrended values. Let $s$ be the length of the seasonal period, and $q$ be the degree of the polynomial used in the seasonal smoother. The seasonal values, $\\hat{S}_t$, are given by:\n",
    "\n",
    "$$ \\hat{S}t = \\frac{1}{K} \\sum{j=1}^K y^*_{t + (j-1)s} $$\n",
    "\n",
    "where $K = \\lfloor \\frac{T}{s} \\rfloor$ is the number of seasonal periods in the time series.\n",
    "\n",
    "- **Deseasonalizing**:\n",
    "\n",
    "The deseasonalized values, $y^{**}_t$, are obtained by dividing the detrended values by the seasonal values:\n",
    "\n",
    "$$ y^{**}_t = \\frac{y^*_t}{\\hat{S}_t} $$\n",
    "\n",
    "- **Residual Smoothing**:\n",
    "\n",
    "The remainder component is obtained by applying a smoother to the deseasonalized values. Let $r$ be the degree of the polynomial used in the residual smoother. The smoothed residuals, $\\hat{R}_t$, are given by:\n",
    "\n",
    "$$ \\hat{R}t = \\sum{j=1}^r c_j \\epsilon_{t-j} $$\n",
    "\n",
    "where $c_j$ are the smoothing parameters, and $\\epsilon_{t-j}$ are the residuals at time $t-j$.\n",
    "\n",
    "- **Reconstruction**:\n",
    "\n",
    "The final step in STL is to add the trend, seasonal and remainder components back together to obtain the reconstructed values, $\\hat{y}_t$:\n",
    "\n",
    "$$ \\hat{y}_t = \\hat{T}_t + \\hat{S}_t \\cdot y^{**}_t + \\hat{R}_t $$\n",
    "\n",
    "> **STL can be useful for predicting Bitcoin prices when there are seasonal patterns or trends in the data.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "\n",
    "- Data: Time series data with seasonal patterns. Two sources of such data are FRED (Federal Reserve Economic Data) and Yahoo Finance.\n",
    "- Best input: The time series data with seasonal patterns.\n",
    "- Best output: Decomposition of the time series into its seasonal, trend, and remainder components.\n",
    "- Models that can be combined: ARIMA, VAR, and GARCH models.\n",
    "\n",
    "## Multivariate GARCH (MGARCH) models: Developed by Robert Engle in the 1990s\n",
    "\n",
    "Developed by Robert Engle in the 1990s, the MGARCH model is an extension of the univariate GARCH model to multivariate time series. It models the conditional variance of each series as a function of its own lagged values and the lagged values of the other series in the system. The mathematical equation for a MGARCH(p, q) model is as follows:\n",
    "\n",
    "$$\\boldsymbol{\\Sigma}_{t} = \\boldsymbol{A}_{0} + \\sum_{i=1}^{p} \\boldsymbol{A}_{i} \\boldsymbol{\\epsilon}_{t-i} \\boldsymbol{\\epsilon}_{t-i}^{\\prime} \\boldsymbol{A}_{i}^{\\prime} + \\sum_{j=1}^{q} \\boldsymbol{B}_{j} \\boldsymbol{\\Sigma}_{t-j} \\boldsymbol{B}_{j}^{\\prime}$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $\\boldsymbol{\\Sigma}_{t}$ is the $k \\times k$ covariance matrix of the error terms at time $t$\n",
    "- $\\boldsymbol{A}_{0}$ is the $k \\times k$ intercept matrix\n",
    "- $\\boldsymbol{A}_{i}$ and $\\boldsymbol{B}_{j}$ are $k \\times k$ coefficient matrices for the error term and covariance matrix, respectively.\n",
    "- $p$ and $q$ are the order of autoregression and moving average terms for the error term and covariance matrix, respectively.\n",
    "\n",
    "> **MGARCH can be useful for predicting the interrelationships between different variables that may affect Bitcoin prices, including the volatility of different cryptocurrencies.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "\n",
    "- Data: Multivariate time series data with volatility clustering and spillover effects. Two sources of such data are - FRED and Quandl.\n",
    "- Best input: Historical prices of multiple assets, along with other relevant variables.\n",
    "- Best output: Prediction of future volatility of each asset, and their correlations.\n",
    "- Models that can be combined: VAR, LSTM, and BNN models.\n",
    "\n",
    "## Bayesian Neural Networks (BNN): Bayesian neural networks have been developed by multiple researchers including David MacKay in the 1990s and Radford Neal in 1995\n",
    "\n",
    "The Bayesian neural network model is a type of neural network that incorporates Bayesian inference in the training process. It works by placing a prior distribution over the model parameters and using Bayes' rule to update the posterior distribution of the parameters given the training data. The model uses Monte Carlo methods, such as Markov chain Monte Carlo (MCMC), to approximate the posterior distribution.\n",
    "\n",
    "The mathematical equation for the Bayesian neural network model is as follows:\n",
    "\n",
    "Given a training set ${(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)}$, where $x_i$ is the input data and $y_i$ is the corresponding output, the goal is to find a function $f(x)$ that predicts the output $y$ for a given input $x$.\n",
    "\n",
    "The Bayesian neural network model places a prior distribution $p(w)$ over the model parameters $w$ and uses Bayes' rule to update the posterior distribution $p(w|D)$ of the parameters given the training data $D$:\n",
    "\n",
    "$$p(w|D) = \\frac{p(D|w) p(w)}{p(D)}$$\n",
    "\n",
    "where $p(D|w)$ is the likelihood of the data given the parameters, $p(w)$ is the prior distribution, and $p(D)$ is the marginal likelihood of the data.\n",
    "\n",
    "> **BNN can be useful for predicting Bitcoin prices based on a large set of input data, where the relationships between the input and output variables may be complex and nonlinear.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Time series data with complex nonlinear relationships. Two sources of such data are Kaggle and GitHub.\n",
    "- Best input: Historical prices and related variables as input features.\n",
    "- Best output: Prediction of future prices and their uncertainty.\n",
    "- Models that can be combined: SVR, LSTM, and Random Forest models.\n",
    "\n",
    "## Long Short-Term Memory (LSTM) models: Developed by Sepp Hochreiter and Jürgen Schmidhuber in 1997\n",
    "\n",
    "LSTM models are a type of recurrent neural network that are designed to capture long-term dependencies in time series data. The equations for an LSTM cell are:\n",
    "\n",
    "$$f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f)$$\n",
    "\n",
    "$$i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i)$$\n",
    "\n",
    "$$\\tilde{C}t = \\tanh(W_C x_t + U_C h{t-1} + b_C)$$\n",
    "\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
    "\n",
    "$$o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o)$$\n",
    "\n",
    "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
    "\n",
    "where $x_t$ is the input at time $t$, $h_{t-1}$ is the previous hidden state, $W_f, U_f, b_f$ are the weights and bias for the forget gate, $W_i, U_i, b_i$ are the weights and bias for the input gate, $W_C, U_C, b_C$ are the weights and bias for the cell state, $W_o, U_o, b_o$ are the weights and bias for the output gate, $\\sigma(\\cdot)$ is the sigmoid activation function.\n",
    "\n",
    "> **LSTM can be useful for predicting Bitcoin prices based on a large set of input data, where the relationships between the input and output variables may be complex and nonlinear, and where there may be time lags in the data.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Time series data with temporal dependencies and long-term memory. Two sources of such data are CoinDesk and Yahoo Finance.\n",
    "- Best input: Historical prices and related variables as input features.\n",
    "- Best output: Prediction of future prices.\n",
    "- Models that can be combined: ARIMA, SVR, and Random Forest models.\n",
    "\n",
    "\n",
    "## Heterogeneous agent model developed by Brock and Hommes, 1998\n",
    "\n",
    "The first model we use is based on the standard framework for estimating the speculative bubble component in asset prices. This model assumes that asset prices can be decomposed into two components: a fundamental component and a speculative component. The fundamental component is driven by the intrinsic value of the asset, while the speculative component is driven by market sentiment and investors' expectations.\n",
    "\n",
    "To estimate the fundamental component of Bitcoin prices, we use a range of economic indicators, including the hash rate, transaction volume, and mining difficulty. We also consider the macroeconomic environment, such as inflation rates and interest rates, to account for the broader economic context in which Bitcoin operates.\n",
    "\n",
    "To estimate the speculative component of Bitcoin prices, we use a variety of technical indicators, including moving averages, relative strength index (RSI), and the stochastic oscillator. We also use sentiment analysis of social media and news articles to gauge market sentiment and investor expectations.\n",
    "\n",
    "The Heterogeneous agent model developed by Brock and Hommes (1998) assumes that the asset price $P_t$ can be decomposed into a fundamental component $F_t$ and a speculative component $S_t$ as follows:\n",
    "\n",
    "$$P_t = F_t + S_t$$\n",
    "\n",
    "The fundamental component of Bitcoin prices can be estimated using the following equation:\n",
    "\n",
    "$$F_t = \\omega_0 + \\sum_{j=1}^{N} \\omega_j X_{j,t}$$\n",
    "\n",
    "where $F_t$ is the fundamental component of Bitcoin prices at time $t$, $X_{j,t}$ are the **economic indicators** and **macroeconomic factors** at time $t$, $N$ is the total number of indicators and factors, and $\\omega_j$ are the corresponding weights.\n",
    "\n",
    "$$ F_t = \\omega_0 + w_1 \\cdot \\text{hash rate}_t + w_2 \\cdot \\text{transaction volume}_t + w_3 \\cdot \\text{mining difficulty}_t + w_4 \\cdot \\text{inflation rates}_t + w_5 \\cdot \\text{interest rates}_t $$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $F_t$ is the fundamental component of Bitcoin prices at time $t$\n",
    "- $\\text{hash rate}_t$ is the hash rate of the Bitcoin network at time $t$\n",
    "- $\\text{transaction volume}_t$ is the transaction volume on the Bitcoin network at time $t$\n",
    "- $\\text{mining difficulty}_t$ is the mining difficulty of the Bitcoin network at time $t$\n",
    "- $\\text{inflation rates}_t$ is the inflation rate at time $t$\n",
    "- $\\text{interest rates}_t$ is the interest rate at time $t$\n",
    "- $w_1, w_2, w_3, w_4,$ and $w_5$ are weights assigned to each of the economic indicators and macroeconomic factors, respectively.\n",
    "\n",
    "The speculative component of Bitcoin prices can be estimated using the following equation:\n",
    "\n",
    "$$S_t = \\sum_{j=1}^{M} \\alpha_j Y_{j,t} + \\beta S_{t-1}$$\n",
    "\n",
    "where $S_t$ is the speculative component of Bitcoin prices at time $t$, $Y_{j,t}$ are the **technical indicators** and **sentiment analysis** at time $t$, $M$ is the total number of technical indicators and sentiment analysis, $\\alpha_j$ are the corresponding weights, and $\\beta$ is the persistence parameter.\n",
    "\n",
    "$Y_{j,t}$, which represents the $j$th technical indicator or sentiment analysis at time $t$, can be written as:\n",
    "\n",
    "$$Y_{j,t} = f_j (P_t, V_t, M_t, N_t, S_t, A_t, E_t)$$\n",
    "\n",
    "where $P_t$ is the price of Bitcoin at time $t$, $V_t$ is the trading volume of Bitcoin at time $t$, $M_t$ is the mining difficulty of Bitcoin at time $t$, $N_t$ is the number of active Bitcoin nodes at time $t$, $S_t$ is the market sentiment of Bitcoin at time $t$, $A_t$ is the adoption rate of Bitcoin at time $t$, and $E_t$ is the external news and events related to Bitcoin at time $t$. The function $f_j$ represents the specific technical indicator or sentiment analysis being used, and may have different inputs and parameters depending on the indicator.\n",
    "\n",
    "For example, the formula for the **moving average** indicator ($MA$) with a window size of $k$ can be written as:\n",
    "\n",
    "$$Y_{MA,t} = \\frac{1}{k} \\sum_{i=t-k+1}^{t} P_i$$\n",
    "\n",
    "where $P_i$ is the price of Bitcoin at time $i$.\n",
    "\n",
    "Similarly, the formula for the **relative strength index** ($RSI$) with a window size of $k$ can be written as:\n",
    "\n",
    "$$Y_{RSI,t} = 100 - \\frac{100}{1 + RS}$$\n",
    "\n",
    "where $RS$ is the relative strength at time $t$, which is calculated as:\n",
    "\n",
    "$$RS = \\frac{\\sum_{i=t-k+1}^{t} Max(P_i - P_{i-1}, 0)}{\\sum_{i=t-k+1}^{t} |P_i - P_{i-1}|}$$\n",
    "\n",
    "The formula for the **stochastic oscillator** ($SO$) with a window size of $k$ can be written as:\n",
    "\n",
    "$$Y_{SO,t} = \\frac{P_t - Min_{k}(P)}{Max_{k}(P) - Min_{k}(P)} \\times 100$$\n",
    "\n",
    "where $Min_{k}(P)$ and $Max_{k}(P)$ are the minimum and maximum prices of Bitcoin over the past $k$ periods, respectively.\n",
    "\n",
    "The **sentiment analysis** indicator ($SA$) at time $t$ can be written as:\n",
    "\n",
    "$$Y_{SA,t} = f_{SA}(T_t, A_t, E_t)$$\n",
    "\n",
    "where $T_t$ is the text data extracted from news articles and social media related to Bitcoin at time $t$, and $f_{SA}$ is a function that processes the text data to generate a sentiment score. The sentiment score may be based on techniques such as keyword analysis, natural language processing, or machine learning.\n",
    "\n",
    "> **This model can be useful for predicting how different types of market participants, such as traders and investors, may behave and how this may affect Bitcoin prices.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Time series data with behavioral aspects of market participants. Two sources of such data are BitcoinTalk forum and Twitter.\n",
    "- Best input: Historical prices and sentiment data as input features.\n",
    "- Best output: Prediction of future prices and identification of market regimes.\n",
    "- Models that can be combined: VAR, MSGARCH, and LSTM models.\n",
    "\n",
    "## Shiller's CAPE Ratio, 2000\n",
    "\n",
    "Shiller's CAPE ratio has been applied to the valuation of Bitcoin in the literature. However, it is important to note that the applicability of traditional stock market valuation models, such as the CAPE ratio, to the cryptocurrency market is still a matter of debate and further research is needed to determine their effectiveness in predicting Bitcoin prices.\n",
    "\n",
    "The cyclically adjusted price-to-earnings (CAPE) ratio, also known as the Shiller PE ratio, is a valuation measure that uses real earnings per share over a 10-year period to smooth out fluctuations in corporate profits that occur over different periods of the business cycle. The formula for calculating the CAPE ratio is as follows:\n",
    "\n",
    "$$CAPE = \\frac{P}{E_{10}}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$P$ is the price of the asset\n",
    "$E_{10}$ is the average of the inflation-adjusted earnings of the asset over the previous 10 years\n",
    "\n",
    "> **This model can be useful for predicting when the Bitcoin market may be overvalued or undervalued based on historical price data.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "\n",
    "- Data: Time series data of the cyclically-adjusted price-to-earnings (CAPE) ratio. Two sources of such data are Yale University and FRED.\n",
    "- Best input: Historical CAPE ratio as input feature.\n",
    "- Best output: Prediction of future prices.\n",
    "- Models that can be combined: ARIMA, VAR, and Random Forest models.\n",
    "\n",
    "## Markov switching GARCH (MSGARCH) models: Developed by Robert Engle and Kevin Sheppard in the 2000s\n",
    "\n",
    "The MSGARCH model combines the GARCH model with a Markov regime-switching model to account for changes in volatility over time. The MSGARCH model assumes that the variance of the time series is dependent on the state of an unobservable Markov chain. The state of the Markov chain determines the volatility of the time series.\n",
    "\n",
    "Let $y_t$ be a $K \\times 1$ vector of variables at time $t$, and $h_t$ be the conditional variance-covariance matrix of $y_t$ given the information set $F_{t-1}$. The MSGARCH model can be written as:\n",
    "\n",
    "$$h_t = A_{s_t} + \\sum_{i=1}^p B_i y_{t-i} y_{t-i}' B_i' + \\sum_{j=1}^q C_j h_{t-j} C_j'$$\n",
    "\n",
    "where $s_t$ is the state of the Markov chain at time $t$, $A_{s_t}$ is a $K \\times K$ matrix that contains the unconditional variance-covariance matrix of $y_t$ in state $s_t$, and $B_i$ and $C_j$ are coefficient matrices.\n",
    "\n",
    "> **MSGARCH can be useful for predicting changes in market regimes and how they may affect the volatility of Bitcoin prices.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data of Bitcoin, including volatility measures such as GARCH residuals\n",
    "- Sources: Cryptocurrency exchanges, financial data providers such as Bloomberg or Yahoo Finance\n",
    "- Best input: Historical price data of Bitcoin and other relevant cryptocurrencies, as well as relevant macroeconomic indicators that may affect the cryptocurrency market\n",
    "- Best output: Predictions of future volatility of Bitcoin and other cryptocurrencies\n",
    "- Combination models: Random Forest, LSTM, SVR\n",
    "\n",
    "## Random Forest model: Developed by Leo Breiman in 2001\n",
    "\n",
    "The random forest model is an ensemble learning algorithm used for classification and regression analysis. It works by constructing a multitude of decision trees at training time and outputting the class or mean prediction of the individual trees. The random forest model reduces overfitting by aggregating the results of many decision trees.\n",
    "\n",
    "The mathematical equation for the random forest model is as follows:\n",
    "\n",
    "Given a training set ${(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)}$, where $x_i$ is the input data and $y_i$ is the corresponding output, the goal is to find a function $f(x)$ that predicts the output y for a given input $x$.\n",
    "\n",
    "The random forest model constructs $M$ decision trees, each of which is trained on a bootstrapped sample of the training data. At each node of a decision tree, a random subset of the input features is considered for splitting.\n",
    "\n",
    "The prediction of the random forest model is obtained by averaging the predictions of the individual decision trees:\n",
    "\n",
    "$$f(x) = \\frac{1}{M} \\sum_{j=1}^M f_j(x)$$\n",
    "\n",
    "where $f_j(x)$ is the prediction of the $j-th$ decision tree.\n",
    "\n",
    "> **Random Forest can be useful for predicting Bitcoin prices based on a large set of input data, where the relationships between the input and output variables may be nonlinear and difficult to model.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "\n",
    "- Data: Historical price data of Bitcoin, including various technical indicators such as moving averages, relative strength index (RSI), and stochastic oscillator\n",
    "- Sources: Cryptocurrency exchanges, technical analysis platforms such as TradingView or Coinigy\n",
    "- Best input: Historical price data of Bitcoin and other relevant cryptocurrencies, as well as relevant macroeconomic indicators that may affect the cryptocurrency market\n",
    "- Best output: Predictions of future price movements of Bitcoin and other cryptocurrencies\n",
    "- Combination models: LSTM, SVR, MSGARCH\n",
    "\n",
    "## ARIMA-NN, a Time series forecasting using a hybrid ARIMA and neural network model by Zhang, G. P., 2003\n",
    "\n",
    "The hybrid ARIMA and neural network model proposed by Zhang (2003) combines the strengths of the Autoregressive Integrated Moving Average (ARIMA) model and neural network models to improve the accuracy of time series forecasting. The model is based on the following equation:\n",
    "\n",
    "$$\\hat{y}{t+h|t}=y_t + \\sum{i=1}^{p}\\phi_i(y_{t+1-i}-y_t) + \\sum_{j=1}^{q}\\theta_j\\varepsilon_{t+1-j} + f(y_t, y_{t-1},..., y_{t-p}, \\varepsilon_{t-1}, \\varepsilon_{t-2}, ..., \\varepsilon_{t-q})$$\n",
    "\n",
    "where $\\hat{y}_{t+h|t}$ is the forecast for time $t+h$, given data up to time $t$; $p$ and $q$ are the orders of the autoregressive and moving average parts of the ARIMA model, respectively; $\\phi_i$ and $\\theta_j$ are the corresponding coefficients; $\\varepsilon_t$ is the error term; and $f$ is a neural network model that captures any nonlinear patterns in the data.\n",
    "\n",
    "The neural network component of the model is trained using a backpropagation algorithm to minimize the mean squared error between the actual and predicted values. The weights of the neural network are updated iteratively during the training process until convergence.\n",
    "\n",
    "The hybrid ARIMA and neural network model has been shown to outperform traditional time series models in many applications, including forecasting stock prices, exchange rates, and electricity demand.\n",
    "\n",
    "> **This model can be useful for predicting Bitcoin prices based on a combination of time series analysis and machine learning techniques.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data of Bitcoin\n",
    "- Sources: Cryptocurrency exchanges, financial data providers such as Bloomberg or Yahoo Finance\n",
    "- Best input: Historical price data of Bitcoin and other relevant cryptocurrencies, as well as relevant macroeconomic indicators that may affect the cryptocurrency market\n",
    "- Best output: Predictions of future price movements of Bitcoin and other cryptocurrencies\n",
    "- Combination models: Random Forest, LSTM, SVR\n",
    "\n",
    "## Modified version of the model proposed by Phillips et al., 2011\n",
    "\n",
    "The second model we use is based on the behavioral finance literature, which suggests that investors' irrational behavior can create speculative bubbles in financial markets.\n",
    "\n",
    "This model assumes that market sentiment and investor behavior are driven by a range of psychological biases, including herding behavior, overconfidence, and confirmation bias.\n",
    "\n",
    "The modified Phillips et al. (2011) model for detecting speculative bubbles in financial markets is defined by the following equation:\n",
    "\n",
    "$$y_t = \\beta_0 + \\beta_1x_{1,t} + \\beta_2x_{2,t} + \\beta_3x_{3,t} + \\epsilon_t$$\n",
    "\n",
    "where,\n",
    "\n",
    "$y_t$ is the log of the price of the asset at time $t$\n",
    "$x_{1,t}$ is the log of the ratio of the market capitalization of the asset to the market capitalization of all cryptocurrencies\n",
    "$x_{2,t}$ is the Google Trends search volume index for the term \"Bitcoin\"\n",
    "$x_{3,t}$ is the number of Bitcoin-related tweets and Reddit posts\n",
    "$\\beta_0, \\beta_1, \\beta_2,$ and $\\beta_3$ are the parameters of the model\n",
    "$\\epsilon_t$ is the error term.\n",
    "\n",
    "To estimate the speculative bubble component of Bitcoin prices using this model, we use a range of behavioral finance indicators, including the ratio of Bitcoin to the market capitalization of all cryptocurrencies, the Google Trends search volume index for the term \"Bitcoin,\" and the number of Bitcoin-related tweets and Reddit posts.\n",
    "\n",
    "> **This modified version of the model may be useful for predicting Bitcoin prices based on a combination of statistical and machine learning techniques.**\n",
    "\n",
    "### Model training data, input data, output data, integrations\n",
    "- Data: Historical price data of Bitcoin, as well as various technical indicators such as moving averages, RSI, and MACD\n",
    "- Sources: Cryptocurrency exchanges, technical analysis platforms such as TradingView or Coinigy\n",
    "- Best input: Historical price data of Bitcoin and other relevant cryptocurrencies, as well as relevant macroeconomic indicators that may affect the cryptocurrency market\n",
    "- Best output: Predictions of future price movements of Bitcoin and other cryptocurrencies\n",
    "- Combination models: LSTM, SVR, MSGARCH\n",
    "\n",
    "## References\n",
    "\n",
    "- Keynes, J. M. (1936). The General Theory of Employment, Interest and Money. Palgrave Macmillan.\n",
    "\n",
    "- McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4), 115-133.\n",
    "\n",
    "- Werbos, P. J. (1974). Beyond regression: New tools for prediction and analysis in the behavioral sciences. Ph.D. Thesis, Harvard University.\n",
    "\n",
    "- Rumelhart, D. E., & McClelland, J. L. (1986). Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundations. MIT press.\n",
    "\n",
    "- Hinton, G. (2007). Learning multiple layers of representation. Trends in cognitive sciences, 11(10), 428-434.\n",
    "\n",
    "- Jeffreys, H. (1946). An invariant form for the prior probability in estimation problems. Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences, 186(1007), 453-461.\n",
    "\n",
    "- De Finetti, B. (1951). Su un'impostazione alternativa dell'analisi statistica dei dati: (contributo alla teoria delle indagini statistiche). Rome: Comitato per la pubblicazione delle opere di B. de Finetti.\n",
    "\n",
    "- Granger, C. W. J. (1969). Investigating causal relations by econometric models and cross-spectral methods. Econometrica, 37(3), 424-438.\n",
    "\n",
    "- Box, G. E., & Jenkins, G. M. (1970). Time series analysis: forecasting and control. San Francisco: Holden-Day.\n",
    "\n",
    "- Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation. Econometrica, 50(4), 987-1008.\n",
    "\n",
    "- Harvey, A. C. (1989). Forecasting, structural time series models and the Kalman filter. Cambridge University Press.\n",
    "\n",
    "- Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I. (1990). STL: A seasonal-trend decomposition. Journal of Official Statistics, 6(1), 3-73.\n",
    "\n",
    "- Vapnik, V. N., & Chervonenkis, A. Y. (1995). Theory of pattern recognition (NATO ASI Series F: Computer and System Sciences). Springer-Verlag.\n",
    "\n",
    "- Sornette, D. (1998). Discrete-scale invariance and complex dimensions. Physics Reports, 297(5-6), 239-270.\n",
    "\n",
    "- Engle, R. F. (2001). GARCH 101: The use of ARCH/GARCH models in applied econometrics. Journal of Economic Perspectives, 15(4), 157-168.\n",
    "\n",
    "- Brock, W. A., & Hommes, C. H. (1998). Heterogeneous beliefs and routes to chaos in a simple asset pricing model. Journal of Economic Dynamics and Control, 22(8-9), 1235-1274.\n",
    "\n",
    "- Shiller, R. J. (2000). Irrational exuberance. Princeton University Press.\n",
    "\n",
    "- Engle, R. F., & Sheppard, K. (2001). Theoretical and empirical properties of dynamic conditional correlation multivariate GARCH. University of California-San Diego.\n",
    "\n",
    "- Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5-32.\n",
    "\n",
    "- Zhang, G. P. (2003). Time series forecasting using a hybrid ARIMA and neural network model. Neurocomputing, 50, 159-175.\n",
    "\n",
    "- Phillips, P. C., Wu, Y., & Yu, J. (2011). Explosive behavior in the 1990s NASDAQ: When did exuberance escalate asset values?. International Economic Review, 52(1), 201-226.\n",
    "\n",
    "- Coin Metrics. (2023). Community network data. Retrieved February 28, 2023, from https://coinmetrics.io/community-network-data/\n",
    "\n",
    "- Google Trends. (2023). Bitcoin search interest. Retrieved February 28, 2023, from https://trends.google.com/trends/explore?date=all&q=bitcoin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
