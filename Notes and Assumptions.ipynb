{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f398ddad",
   "metadata": {},
   "source": [
    "# Notes and Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58db7a",
   "metadata": {},
   "source": [
    "# Model 1 - Heterogeneous agent model developed by Brock and Hommes (1998)\n",
    "\n",
    "The sentiment analysis indicator ($SA$) at time $t$ can be written as:\n",
    "\n",
    "$$Y_{SA,t} = f_{SA}(T_t, A_t, E_t)$$\n",
    "\n",
    "where $T_t$ is the text data extracted from news articles and social media related to Bitcoin at time $t$, and $f_{SA}$ is a function that processes the text data to generate a sentiment score. The sentiment score may be based on techniques such as keyword analysis, natural language processing, or machine learning.\n",
    "\n",
    "> We didn't use this indicator just yet because of the lack of the data provided on it\n",
    "\n",
    "The model is more or less a linear combination of bitcoin features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk = pd.read_csv(\"datasets/btc_tweets.csv\", chunksize=100000, lineterminator='\\n')\n",
    "# btc_tweets = pd.concat(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# text = 'Bitcoin is soaring to new heights!'\n",
    "# btc['SA'] = btc.apply(lambda row: sentiment_analysis(row['Text']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c35c4b",
   "metadata": {},
   "source": [
    "> btc sentiment data is not much findable for dates before 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16241794",
   "metadata": {},
   "source": [
    "> Dropping some NaN values du to indicators, parameter = $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4cf6f4",
   "metadata": {},
   "source": [
    "Add the saving to the calculation part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24253498",
   "metadata": {},
   "source": [
    "## Model 2 - WARMA-NN\n",
    "\n",
    "- Strengths of ARIMA model:\n",
    "\n",
    "ARIMA models are easy to understand and interpret.\n",
    "ARIMA models can handle a wide range of stationary time series data, including those with a linear trend and seasonality.\n",
    "ARIMA models can provide reliable short-term forecasts.\n",
    "ARIMA models can be used to model univariate time series data.\n",
    "\n",
    "- Weaknesses of ARIMA model:\n",
    "\n",
    "ARIMA models are not suitable for modeling non-stationary time series data.\n",
    "ARIMA models are limited to modeling linear relationships between variables.\n",
    "ARIMA models require a large amount of historical data to be effective.\n",
    "\n",
    "- Opportunities for ARIMA model:\n",
    "\n",
    "ARIMA models can be easily adapted to include external factors that may influence the time series data.\n",
    "ARIMA models can be used in combination with other models, such as machine learning models, to improve forecast accuracy.\n",
    "\n",
    "- Threats to ARIMA model:\n",
    "\n",
    "ARIMA models may not be effective in predicting long-term trends or major shifts in the data.\n",
    "ARIMA models may not be able to capture complex relationships between variables.\n",
    "ARIMA models can be computationally intensive and may require significant processing power to train.\n",
    "\n",
    "- Strengths of VARMA model:\n",
    "\n",
    "VARMA models can capture complex relationships between multiple variables.\n",
    "VARMA models can handle non-stationary time series data.\n",
    "VARMA models can provide accurate short-term and long-term forecasts.\n",
    "VARMA models can be used to model multivariate time series data.\n",
    "\n",
    "- Weaknesses of VARMA model:\n",
    "\n",
    "VARMA models can be difficult to interpret and understand.\n",
    "VARMA models require a large amount of data to train effectively.\n",
    "VARMA models can be computationally intensive and may require significant processing power to train.\n",
    "\n",
    "- Opportunities for VARMA model:\n",
    "\n",
    "VARMA models can be used to identify causal relationships between variables.\n",
    "VARMA models can be used to identify leading indicators for forecasting.\n",
    "VARMA models can be used in combination with other models, such as machine learning models, to improve forecast accuracy.\n",
    "\n",
    "- Threats to VARMA model:\n",
    "\n",
    "VARMA models may not be effective in modeling time series data with irregular patterns.\n",
    "VARMA models may be sensitive to outliers in the data.\n",
    "VARMA models may be difficult to implement and require specialized knowledge to train effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7e068",
   "metadata": {},
   "source": [
    "## Model 3: ARIMA-NN + Heterogenous Agent Model\n",
    "\n",
    "First, the ARIMA and NN models are widely used and well-established models for predicting time series data. ARIMA models are particularly useful for capturing trend and seasonality in the data, while NN models are good at identifying complex relationships between input variables and the output. By combining these models, we can leverage their strengths and improve the accuracy of our predictions.\n",
    "\n",
    "Second, a heterogenous agent model can help us account for the diversity of agents in the bitcoin market, each with their own set of preferences and behaviors. By modeling these agents and how they interact with each other, we can better understand the dynamics of the market and make more accurate predictions.\n",
    "\n",
    "Third, by using indicators as inputs to our models, we can incorporate a wide range of data into our predictions, including both technical and fundamental factors that may affect the bitcoin market. This can lead to more robust and accurate predictions that take into account a variety of factors that may influence bitcoin prices.\n",
    "\n",
    "Finally, the ability to combine different models into a single framework allows us to capitalize on the strengths of each model while minimizing their weaknesses. This can help us produce more accurate and reliable predictions, which can be crucial for making informed decisions in the volatile and unpredictable world of cryptocurrency trading.\n",
    "\n",
    "In conclusion, by combining ARIMA and NN models with a heterogenous agent model, we can develop a powerful framework for predicting bitcoin prices that takes into account a wide range of factors and can produce accurate and reliable predictions. While there are no guarantees in the world of cryptocurrency trading, this approach provides a solid foundation for making informed decisions and minimizing risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d7b7c",
   "metadata": {},
   "source": [
    "## Model N: Fundamental Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71aebc6",
   "metadata": {},
   "source": [
    "## Model 2 - Time-Series of the economic and macroeconomic factors and of the technical indicators and sentiment analysis\n",
    "\n",
    "In this model, we try to forecast the bitcoin features and indicators using time-series techniques.\n",
    "\n",
    "Here are the indicatiors we'd be trying to forecast:\n",
    "\n",
    "- $H_t$ is the hash rate of the Bitcoin network at time $t$\n",
    "- $TV_t$ is the transaction volume on the Bitcoin network at time $t$\n",
    "- $MD_t$ is the mining difficulty of the Bitcoin network at time $t$\n",
    "- $IR_t$ is the inflation rate at time $t$\n",
    "\n",
    "- The moving average indicator ($MA$) \n",
    "\n",
    "For example, the formula for the moving average indicator ($MA$) with a window size of $k$ can be written as:\n",
    "\n",
    "$$Y_{MA,t} = \\frac{1}{k} \\sum_{i=t-k+1}^{t} P_i$$\n",
    "\n",
    "where $P_i$ is the price of Bitcoin at time $i$.\n",
    "\n",
    "- The relative strength index ($RSI$)\n",
    "\n",
    "Similarly, the formula for the relative strength index ($RSI$) with a window size of $k$ can be written as:\n",
    "\n",
    "$$Y_{RSI,t} = 100 - \\frac{100}{1 + RS}$$\n",
    "\n",
    "where $RS$ is the relative strength at time $t$, which is calculated as:\n",
    "\n",
    "$$RS = \\frac{\\sum_{i=t-k+1}^{t} Max(P_i - P_{i-1}, 0)}{\\sum_{i=t-k+1}^{t} |P_i - P_{i-1}|}$$\n",
    "\n",
    "- The stochastic oscillator ($SO$)\n",
    "\n",
    "The formula for the stochastic oscillator ($SO$) with a window size of $k$ can be written as:\n",
    "\n",
    "$$Y_{SO,t} = \\frac{P_t - Min_{k}(P)}{Max_{k}(P) - Min_{k}(P)} \\times 100$$\n",
    "\n",
    "where $Min_{k}(P)$ and $Max_{k}(P)$ are the minimum and maximum prices of Bitcoin over the past $k$ periods, respectively.\n",
    "\n",
    "- The Google Trend indicator $f_{GT}(Q_t)$\n",
    "\n",
    "Another $f_j$ can be the Google Trend indicator $f_{GT}(Q_t)$\n",
    "\n",
    "$$Y_{GT,t} = f_{GT}(Q_t)$$\n",
    "\n",
    "where $Q_t$ represents the search query related to Bitcoin at time $t$, and $f_{GT}$ is a function that processes the search data to generate a Google Trends score.\n",
    "\n",
    "The Google Trends score is a relative measure of the search interest for a particular query over time. It is calculated by normalizing the search volume for a given query over a specific time period and location to the total search volume for all queries in that time period and location. The resulting score ranges from 0 to 100, with 100 indicating the highest relative search interest.\n",
    "\n",
    "Here is a step-by-step guide on how to build a model to forecast economic and macroeconomic indicators, technical indicators, and sentiment analysis for predicting future values:\n",
    "\n",
    "1. **Gather data**: To build a model, we gather data on the economic and macroeconomic indicators, technical indicators, and sentiment analysis. We can obtain this data from public sources such as financial databases, news articles, and social media.\n",
    "\n",
    "2. **Pre-process the data**: Once we have gathered the data, we  pre-process it to make it ready for analysis. This involves cleaning the data, handling missing values, and transforming the data into a format suitable for analysis.\n",
    "\n",
    "3. **Perform feature selection**: Feature selection involves identifying the most relevant features for the model. We use techniques such as correlation analysis, principal component analysis (PCA), and mutual information to select the most important features.\n",
    "\n",
    "4. **Build the model**: There are various models we use to forecast future values, such as regression models, time-series models, and machine learning models. For example, we use a linear regression model to predict the future value of Bitcoin based on the historical values of economic and macroeconomic indicators, technical indicators, and sentiment analysis.\n",
    "\n",
    "5. **Evaluate the model**: After building the model, we evaluate its performance. We use techniques such as cross-validation and residual analysis to assess the model's accuracy and determine if it meets our requirements.\n",
    "\n",
    "6. **Refine the model**: Based on the evaluation, we refine the model by adjusting the model parameters or selecting a different model altogether.\n",
    "\n",
    "6. **Make predictions**: Once we are satisfied with the model's performance, we use it to make predictions about future values. However, it's important to note that the accuracy of the predictions may vary based on the quality of the data and the assumptions made in the model.\n",
    "\n",
    "### Linear regression model:\n",
    "\n",
    "\\begin{equation}\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "where Y is the dependent variable (e.g. Bitcoin's future value), X1, X2, ... Xn are the independent variables (e.g. economic indicators, technical indicators, sentiment analysis), β0, β1, β2, ... βn are the coefficients, and ε is the error term.\n",
    "\n",
    "### PCA:\n",
    "\n",
    "\\begin{equation}\n",
    "T = XW\n",
    "\\end{equation}\n",
    "\n",
    "where T is the transformed data, X is the original data, and W is the weight matrix.\n",
    "\n",
    "### Mutual information:\n",
    "\n",
    "\\begin{equation}\n",
    "I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x,y) \\log{\\frac{p(x,y)}{p(x)p(y)}}\n",
    "\\end{equation}\n",
    "\n",
    "where I(X;Y) is the mutual information between X and Y, p(x,y) is the joint probability distribution, and p(x) and p(y) are the marginal probability distributions.\n",
    "\n",
    "### References:\n",
    "\n",
    "- J. Y. Campbell, A. W. Lo, and A. C. MacKinlay, The Econometrics of Financial Markets, Princeton University Press, 1997.\n",
    "- J. Moody and M. Saffell, \"Extracting Historical Patterns from Textual Data,\" in Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Diego, CA, USA, August 20-23, 1999, pp. 8-15.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
